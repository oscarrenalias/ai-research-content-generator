# Size of the batches of posts to be analyzed. Can greatly speed things up if there are lots of short posts to be analyzed
ANALYSIS_BATCH_SIZE=5

# Model configuration for post generation
DEFAULT_MODEL=gpt-4o
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=8000

# Style Analyzer Model Configuration. This provides the possibiltiy of using two different models
# in order to optimize performance and cost, e.g., it's really easy to hit token per minute quotas
#Â if only using gpt-4o for everything depending on the performance tier, number of posts being analyzed, etc
# Model for batch processing (structural, tone, engagement analysis)
ANALYZER_BATCH_MODEL=gpt-4o-mini
# Model for final synthesis and style prompt generation
ANALYZER_SYNTHESIS_MODEL=gpt-4o

# OpenAI endpoint configuration
OPENAI_API_KEY=sk-proj-yourkeyhere

# Tavily API Configuration
# Visit https://www.tavily.com/ to create a free account and get your API key
TAVILY_API_KEY=tvly-dev-yourkeyhere