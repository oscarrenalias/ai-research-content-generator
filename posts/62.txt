I found this article very enlightening, it validates and articulates so many concerns about OpenAI that Iâ€™ve observed and shared for some time: https://techcrunch.com/2025/10/10/the-fixers-dilemma-chris-lehane-and-openais-impossible-mission/. 

I find it interesting that OpenAI, instead of trying to provide clear answers to key issues, hired someone who is focused on narrative management instead of directly addressing accountability. Iâ€™d rather OpenAI admit that they donâ€™t have all answers (which they donâ€™t) so that we collectively work on the issues together. There's a lot more at stake here than just OpenAI's growth plan.

For starters, intellectual property rights continue to be consistently ignored. OpenAI reportedly trained on thousands of books without compensating creators, and Sora 2 was released with copyrighted materials included. This further complicated matters by offering rights holders only an opt-out process, allowing Sora to generate videos featuring copyrighted characters, or worse, enabling the distribution of AI-generated media to families of deceased public figures.

This is indefensible in my opinion. OpenAI was aware of these risks, but proceeded anyway. As the article says, â€œThatâ€™s not iterating. Thatâ€™s testing how much you can get away withâ€.

Whatâ€™s perhaps even more alarming is that the calls are now coming from inside OpenAI itself. Josh Achiam, OpenAIâ€™s head of mission alignment, recently tweeted â€œWe canâ€™t be doing things that make us into a frightening power instead of a virtuous one. We have a duty to and a mission for all of humanity. The bar to pursue that duty is remarkably high.â€ 

We canâ€™t pretend that â€œship now, explain laterâ€ is harmless when the cost and burden fall on creators, rights holders, and everyday people. When a business consistently tests boundaries instead of seeking consent and accountability, these problems arenâ€™t just accidents but they're the operating model.

It's a difficult issue to address, but this is what not just OpenAI but the whole the AI industry could start with:

ğŸ” Real transparency on training data, backed by independent auditability

ğŸ“ Opt-in licensing and compensation for creators and rights holders by default. Contracts, not vibes and optâ€‘outs

ğŸ› ï¸ Robust provenance/watermarking plus rapid takedown and appeals channels

ğŸ‘¥ Independent oversight with published red-team results and clear timelines

ğŸ›¡ï¸ Comprehensive guardrails to shield young minds and vulnerable usersâ€”proactively prevent exposure to harmful AI content, support mental health, and address recent safety controversies

ğŸŒ Transparent governance of foundation models governed by a global entity, such as the UN or a newly created authority, to ensure AI serves the interest of all humanity 

OpenAIâ€”and the industry at large should meet creators, researchers, broader society and work together to create the guardrails and societal frameworks to succeed. AI is a transformative technology but we can't spin trust, it needs to be earned through the choices we make together.

#AI #AIGovernance #ResponsibleAI